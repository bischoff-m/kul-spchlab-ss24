{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-Sg0pH041mX"
   },
   "source": [
    "# Script for Training Gaussian Mixture Models for TIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "### RUNNING THIS CELL FIRST ##########\n",
    "### will suppresses warnings on memory leaks, deprecation warnings and future warnings \n",
    "### It is brute force .  \n",
    "### Best is not to run it when you want to debug code or new installations\n",
    "import os, warnings \n",
    "os.environ[\"OMP_NUM_THREADS\"] = '2'  \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/compi1234/pyspch.git\n",
    "try:\n",
    "    import pyspch\n",
    "except ModuleNotFoundError:\n",
    "    try:\n",
    "        print(\n",
    "        \"\"\"\n",
    "        To enable this notebook on platforms as Google Colab, \n",
    "        install the pyspch package and dependencies by running following code:\n",
    "\n",
    "        !pip install git+https://github.com/compi1234/pyspch.git\n",
    "        \"\"\"\n",
    "        )\n",
    "    except ModuleNotFoundError:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import io, os, sys\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics as skmetrics \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from IPython.display import display, HTML, Audio\n",
    "\n",
    "# reproducibility \n",
    "np.random.seed(0)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# print and plot\n",
    "mpl.rcParams['figure.figsize'] = [7.,7.]\n",
    "mpl.rcParams['font.size'] = 11\n",
    "np.set_printoptions(precision=3)\n",
    "cmap_jet2 = sns.mpl_palette(\"jet\",60)[5:55]\n",
    "\n",
    "# pyspch\n",
    "import pyspch\n",
    "from pyspch.stats import GMM\n",
    "import pyspch.core as Spch\n",
    "\n",
    "# \n",
    "from pyspch.core.utils_clf import train_GMM, train_MLP, test_clf\n",
    "from pyspch.core.utils_timit import load_timit_data, print_dataset_statistics, select_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Get TIMIT Data and do Feature Extraction\n",
    "\n",
    "#### TIMIT database & Feature Extraction\n",
    "- we read the MEL24 mel filterbank features\n",
    "- postprocess this to obtain MFCC39 features\n",
    "- we'll later select 13, 26, 39 features in different setups\n",
    "\n",
    "At this point all data is stored sequentially sentence-by-sentence.\n",
    "For our classification experiments (main purpose in this notebook) we restructure the data\n",
    "as a long list of frames(feature vectors) with a synchronized list of labels.\n",
    "The classes (set of all labels) are 41 phonetic symbols, i.e. the CMU-39 set + silence + closure.    \n",
    "The labels were obtained from phonetic segmentations that come with the TIMIT database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Xy(data):\n",
    "    X = data.get_features_as_numpy()\n",
    "    y = data.get_labels_as_numpy()\n",
    "    return(X,y)\n",
    "#\n",
    "alphabet = 'timit41'\n",
    "timit41 = pyspch.timit.get_timit_alphabet('timit41')\n",
    "ftrs = \"mel24\"  # \"mel24\" or \"mel80\" are available\n",
    "modify_feature_args = {\"Norm\":\"meanvar\",\"Deltas\":\"delta_delta2\",\"n_cep\":13}\n",
    "#\n",
    "data = load_timit_data(corpus=\"train\",ftrs=ftrs,alphabet=alphabet)\n",
    "data.modify_features(modify_feature_args)\n",
    "X_timit_train, y_timit_train = extract_Xy(data)\n",
    "#\n",
    "data = load_timit_data(corpus=\"test\",ftrs=ftrs,alphabet=alphabet)\n",
    "data.modify_features(modify_feature_args)\n",
    "X_timit_test, y_timit_test = extract_Xy(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistics For the TIMIT Database\n",
    "These are the numbers for the TRAIN database:   \n",
    "Number of speakers 600  \n",
    "Number of samples 1417087   \n",
    "Minimun number of samples per class:  226266   \n",
    "Maximum number of samples per class:  1218 \n",
    "\n",
    "You will note that the data distribution is heavily skewed.\n",
    "This is normal as some phonemes are way more frequent than others.  \n",
    "Moreover the average length of a phoneme plays a role as we take each frame as an observation and just look for the corresponding label in the TIMIT transcriptions.\n",
    "Some phonemes thus have thousands of examples available for training, while others (e.g. 'zh') are only marginally represented, e.g.     \n",
    "The biggest class is 'sil' with 200k+ samples, the biggest phone classes are 's' and 'ih' with 80k+ samples.  The smallest classes are 'b', 'uh' and 'zh' with less than 5000 samples each.  Detailed counts per subdatabase and class are given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for Full Train Database:\n",
      "Number of classes 41\n",
      "Number of samples 1417087\n",
      "Minimun/Maximum number of samples per class:  1218  /  226626\n",
      "[('aa', 37481), ('ae', 59237), ('ah', 39140), ('ao', 36404), ('aw', 11723), ('ay', 34376), ('b', 3823), ('ch', 7116), ('cl', 137933), ('d', 8158), ('dh', 10640), ('eh', 35133), ('er', 51761), ('ey', 28955), ('f', 22828), ('g', 6031), ('hh', 14142), ('ih', 84270), ('iy', 62901), ('jh', 7063), ('k', 25064), ('l', 43515), ('m', 24859), ('n', 46996), ('ng', 8513), ('ow', 26853), ('oy', 11024), ('p', 11482), ('r', 39609), ('s', 84491), ('sh', 25828), ('sil', 226626), ('t', 28720), ('th', 6862), ('uh', 4077), ('uw', 26444), ('v', 12033), ('w', 20946), ('y', 11322), ('z', 31490), ('zh', 1218)]\n",
      "Statistics for Full Test Database:\n",
      "Number of classes 41\n",
      "Number of samples 517845\n",
      "Minimun/Maximum number of samples per class:  643  /  81852\n",
      "[('aa', 14133), ('ae', 21072), ('ah', 14948), ('ao', 14233), ('aw', 3751), ('ay', 12613), ('b', 1562), ('ch', 2244), ('cl', 48675), ('d', 2889), ('dh', 4045), ('eh', 12793), ('er', 21134), ('ey', 10678), ('f', 9413), ('g', 2414), ('hh', 4925), ('ih', 28815), ('iy', 23965), ('jh', 2212), ('k', 8285), ('l', 17596), ('m', 9692), ('n', 16546), ('ng', 2751), ('ow', 10024), ('oy', 4419), ('p', 4204), ('r', 15678), ('s', 30065), ('sh', 9400), ('sil', 81852), ('t', 10100), ('th', 2320), ('uh', 1705), ('uw', 7962), ('v', 4229), ('w', 8610), ('y', 4330), ('z', 10920), ('zh', 643)]\n"
     ]
    }
   ],
   "source": [
    "print_dataset_statistics(y_timit_train,Details=True,txt=\"Full Train Database\")\n",
    "print_dataset_statistics(y_timit_test,Details=True,txt=\"Full Test Database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1:  Use the vow6-database\n",
    "\n",
    "##### Downsampling and data selection\n",
    "For most simple experiments in this notebook we will downsample the full database (typically with a factor 10).   \n",
    "For some experiments we also work with a subset of phonemes only.\n",
    "\n",
    "#### 1.1 Do the Reference Experiment\n",
    "\n",
    "In this experiment we perform vowel recognition from frame data  \n",
    "The experiment is easy in the sense that the used vowels are rather well distinguishable.   \n",
    "The experiment is hard because you base your prediction on a single frame positioned well inside but also at the boundaries of a vowel. \n",
    "\n",
    "We have entered quite reasonable default values in the next cell:\n",
    "- use of static and dynamic MFCCs (26D)\n",
    "- 8 mixtures in the GMM per class\n",
    "- 4 iterations for the GMM training (the KMeans initialization routine does almost all the work, so little will be gained from iterating)\n",
    "- priors are used as derived from the training set (set the priors variable to 'training' or 'uniform')\n",
    "- with these default settings you should achieve an accuracy of approximately 68%  (if you don't get this result, there is probably something wrong in your setup !!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vow6=['iy','aa','uw','ih','eh','er']\n",
    "plosives=['p','t','k','b','d','g']\n",
    "timit41 = pyspch.timit.get_timit_alphabet('timit41')\n",
    "#\n",
    "def gmm_experiment(X_train,y_train,X_test,y_test,classes,ng=1,priors='training',Verbose=False):\n",
    "    kwargs =dict(verbose=0,verbose_interval=1,max_iter=4,init_params='kmeans') \n",
    "    clf_GMM,acc_train = train_GMM(X_train, y_train,  classes=classes, n_components=ng, Verbose=Verbose,**kwargs)\n",
    "    acc_test,cm = test_clf(clf_GMM,X_test, y_test,priors=priors,Verbose=Verbose)\n",
    "    return(clf_GMM,acc_train,acc_test,cm)\n",
    "    \n",
    "def train_gmms(X_train,y_train,classes,ng=1):\n",
    "    kwargs =dict(verbose=0,verbose_interval=1,max_iter=4,init_params='kmeans') \n",
    "    models = []\n",
    "    for nftrs in [13,26,39]:\n",
    "        clf,acc_train = train_GMM(X_train[:,0:nftrs], y_train,  classes=classes, n_components=ng, **kwargs)\n",
    "        models.append(clf)\n",
    "        print(\"Train Accuracy (#FEAT=%d): %.2f%%\" %(nftrs,acc_train) )\n",
    "    return(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for TRAIN:\n",
      "Number of classes 6\n",
      "Number of samples 297990\n",
      "Minimun/Maximum number of samples per class:  26444  /  84270\n",
      "[('aa', 37481), ('eh', 35133), ('er', 51761), ('ih', 84270), ('iy', 62901), ('uw', 26444)]\n",
      "Statistics for TEST:\n",
      "Number of classes 6\n",
      "Number of samples 108802\n",
      "Minimun/Maximum number of samples per class:  7962  /  28815\n",
      "[('aa', 14133), ('eh', 12793), ('er', 21134), ('ih', 28815), ('iy', 23965), ('uw', 7962)]\n"
     ]
    }
   ],
   "source": [
    "classes=vow6\n",
    "X_train, y_train = select_subset(X_timit_train,y_timit_train,labels=classes)\n",
    "X_test, y_test = select_subset(X_timit_test,y_timit_test,labels=classes)\n",
    "print_dataset_statistics(y_train,Details=True,txt=\"TRAIN\")\n",
    "print_dataset_statistics(y_test,Details=True,txt=\"TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:  Accuracy = 61.49%\n",
      "Training Set:  LL(per sample) = -16.06\n",
      "Training Set:  BIC = 9572271.91\n",
      "Accuracy = 62.35%\n",
      "Training Set:  Accuracy = 62.51%\n",
      "Training Set:  LL(per sample) = -15.19\n",
      "Training Set:  BIC = 9062445.59\n",
      "Accuracy = 63.05%\n",
      "Training Set:  Accuracy = 64.10%\n",
      "Training Set:  LL(per sample) = -14.54\n",
      "Training Set:  BIC = 8695761.92\n",
      "Accuracy = 64.21%\n",
      "Training Set:  Accuracy = 62.95%\n",
      "Training Set:  LL(per sample) = -33.87\n",
      "Training Set:  BIC = 20189052.25\n",
      "Accuracy = 63.38%\n",
      "Training Set:  Accuracy = 65.84%\n",
      "Training Set:  LL(per sample) = -31.83\n",
      "Training Set:  BIC = 18983745.09\n",
      "Accuracy = 66.03%\n",
      "Training Set:  Accuracy = 69.12%\n",
      "Training Set:  LL(per sample) = -30.29\n",
      "Training Set:  BIC = 18114963.26\n",
      "Accuracy = 69.16%\n",
      "Training Set:  Accuracy = 60.38%\n",
      "Training Set:  LL(per sample) = -47.66\n",
      "Training Set:  BIC = 28408302.75\n",
      "Accuracy = 60.92%\n",
      "Training Set:  Accuracy = 63.47%\n",
      "Training Set:  LL(per sample) = -43.84\n",
      "Training Set:  BIC = 26150748.41\n",
      "Accuracy = 63.60%\n",
      "Training Set:  Accuracy = 67.38%\n",
      "Training Set:  LL(per sample) = -41.78\n",
      "Training Set:  BIC = 24997854.30\n",
      "Accuracy = 67.34%\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for nftrs in [13,26,39]:\n",
    "    for ng in [1,4,16]:\n",
    "        clf,acc_train,acc_test,cm = gmm_experiment(X_train[:,0:nftrs],y_train, X_test[:,0:nftrs],y_test,classes, ng=ng, Verbose=True)\n",
    "        results.append([nftrs,ng,acc_train,acc_test,clf,cm])\n",
    "results_df = pd.DataFrame([ r[0:4] for r in results],columns=['nftrs','ng','acc_train','acc_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes:  ['iy', 'aa', 'uw', 'ih', 'eh', 'er']\n",
      "Statistics for TRAIN:\n",
      "Number of classes 6\n",
      "Number of samples 297990\n",
      "Minimun/Maximum number of samples per class:  26444  /  84270\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nftrs</th>\n",
       "      <th>ng</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>61.490990</td>\n",
       "      <td>62.350876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>62.514849</td>\n",
       "      <td>63.053988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>64.102487</td>\n",
       "      <td>64.206540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>62.951441</td>\n",
       "      <td>63.379350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>65.839458</td>\n",
       "      <td>66.034632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>69.116413</td>\n",
       "      <td>69.155898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>60.384241</td>\n",
       "      <td>60.920755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>63.468573</td>\n",
       "      <td>63.602691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>67.379442</td>\n",
       "      <td>67.340674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nftrs  ng  acc_train   acc_test\n",
       "0     13   1  61.490990  62.350876\n",
       "1     13   4  62.514849  63.053988\n",
       "2     13  16  64.102487  64.206540\n",
       "3     26   1  62.951441  63.379350\n",
       "4     26   4  65.839458  66.034632\n",
       "5     26  16  69.116413  69.155898\n",
       "6     39   1  60.384241  60.920755\n",
       "7     39   4  63.468573  63.602691\n",
       "8     39  16  67.379442  67.340674"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('classes: ',classes)\n",
    "print_dataset_statistics(y_train,Details=False,txt=\"TRAIN\")\n",
    "#print_dataset_statistics(y_test,Details=False,txt=\"TEST\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:  Accuracy = 43.93%\n",
      "Training Set:  LL(per sample) = -15.70\n",
      "Training Set:  BIC = 44498262.86\n",
      "Accuracy = 43.75%\n",
      "Training Set:  Accuracy = 46.48%\n",
      "Training Set:  LL(per sample) = -14.50\n",
      "Training Set:  BIC = 41213630.63\n",
      "Accuracy = 45.91%\n",
      "Training Set:  Accuracy = 49.55%\n",
      "Training Set:  LL(per sample) = -13.88\n",
      "Training Set:  BIC = 40339821.14\n",
      "Accuracy = 46.82%\n",
      "Training Set:  Accuracy = 47.30%\n",
      "Training Set:  LL(per sample) = -33.53\n",
      "Training Set:  BIC = 95047361.14\n",
      "Accuracy = 46.79%\n",
      "Training Set:  Accuracy = 53.18%\n",
      "Training Set:  LL(per sample) = -30.64\n",
      "Training Set:  BIC = 87075940.92\n",
      "Accuracy = 52.44%\n",
      "Training Set:  Accuracy = 59.47%\n",
      "Training Set:  LL(per sample) = -29.00\n",
      "Training Set:  BIC = 84150432.25\n",
      "Accuracy = 56.36%\n",
      "Training Set:  Accuracy = 45.50%\n",
      "Training Set:  LL(per sample) = -50.70\n",
      "Training Set:  BIC = 143726594.15\n",
      "Accuracy = 44.94%\n",
      "Training Set:  Accuracy = 51.21%\n",
      "Training Set:  LL(per sample) = -46.24\n",
      "Training Set:  BIC = 131428425.11\n",
      "Accuracy = 50.47%\n",
      "Training Set:  Accuracy = 57.65%\n",
      "Training Set:  LL(per sample) = -43.89\n",
      "Training Set:  BIC = 127330610.26\n",
      "Accuracy = 54.62%\n"
     ]
    }
   ],
   "source": [
    "# TRAIN/TEST for full TIMIT\n",
    "X_train = X_timit_train\n",
    "y_train = y_timit_train\n",
    "X_test = X_timit_test\n",
    "y_test = y_timit_test\n",
    "classes = timit41\n",
    "#\n",
    "results = []\n",
    "for nftrs in [13,26,39]:\n",
    "    for ng in [1,8,64]:\n",
    "        clf,acc_train,acc_test,cm = gmm_experiment(X_train[:,0:nftrs],y_train, X_test[:,0:nftrs],y_test,classes, ng=ng, Verbose=True)\n",
    "        results.append([nftrs,ng,acc_train,acc_test,clf,cm])\n",
    "results_df = pd.DataFrame([ r[0:4] for r in results],columns=['nftrs','ng','acc_train','acc_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes:  ['aa', 'ae', 'ah', 'ao', 'aw', 'er', 'ay', 'b', 'ch', 'd', 'dh', 'eh', 'm', 'ng', 'ey', 'f', 'g', 'hh', 'ih', 'iy', 'jh', 'k', 'l', 'n', 'ow', 'oy', 'p', 'r', 's', 'sh', 't', 'th', 'uh', 'uw', 'v', 'w', 'y', 'z', 'zh', 'sil', 'cl']\n",
      "Statistics for TRAIN:\n",
      "Number of classes 41\n",
      "Number of samples 1417087\n",
      "Minimun/Maximum number of samples per class:  1218  /  226626\n",
      "Statistics for TEST:\n",
      "Number of classes 41\n",
      "Number of samples 517845\n",
      "Minimun/Maximum number of samples per class:  643  /  81852\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nftrs</th>\n",
       "      <th>ng</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>43.928566</td>\n",
       "      <td>43.748033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>46.476681</td>\n",
       "      <td>45.906401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>64</td>\n",
       "      <td>49.553838</td>\n",
       "      <td>46.815360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>47.302389</td>\n",
       "      <td>46.793925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>53.181562</td>\n",
       "      <td>52.439630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>64</td>\n",
       "      <td>59.472919</td>\n",
       "      <td>56.364549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>45.498759</td>\n",
       "      <td>44.938350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>51.206030</td>\n",
       "      <td>50.474370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39</td>\n",
       "      <td>64</td>\n",
       "      <td>57.649954</td>\n",
       "      <td>54.615377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nftrs  ng  acc_train   acc_test\n",
       "0     13   1  43.928566  43.748033\n",
       "1     13   8  46.476681  45.906401\n",
       "2     13  64  49.553838  46.815360\n",
       "3     26   1  47.302389  46.793925\n",
       "4     26   8  53.181562  52.439630\n",
       "5     26  64  59.472919  56.364549\n",
       "6     39   1  45.498759  44.938350\n",
       "7     39   8  51.206030  50.474370\n",
       "8     39  64  57.649954  54.615377"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "print('classes: ',classes)\n",
    "print_dataset_statistics(y_train,Details=False,txt=\"TRAIN\")\n",
    "print_dataset_statistics(y_test,Details=False,txt=\"TEST\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Selected Results to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_pickle(data,filename):\n",
    "    picklefile = open(filename, 'wb')\n",
    "    pickle.dump(data, picklefile),\n",
    "    picklefile.close()  \n",
    "GMM39_64 = results[8][4]\n",
    "save_pickle(GMM39_64,\"S41_D39_G64_FULL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ex_timit-3",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
