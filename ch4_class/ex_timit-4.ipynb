{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame Based phoneme recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\compi\\Anaconda3\\envs\\py37\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops_gpu.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-aac23d9fd90c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfftpack\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdct\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#from IPython.display import display\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                 \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrerror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf' Error loading \"{dll}\" or one of its dependencies.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                 \u001b[0mis_loaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\compi\\Anaconda3\\envs\\py37\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops_gpu.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import io, os, sys\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from scipy.fftpack import dct\n",
    "#from IPython.display import display\n",
    "\n",
    "# reproducibility \n",
    "torch.manual_seed(0) \n",
    "np.random.seed(0)\n",
    "\n",
    "# pyspch\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "  ! pip install git+https://github.com/compi1234/pyspch.git@v0.6\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "# pyspch\n",
    "import pyspch\n",
    "import pyspch.nn\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Auxiliary functions \n",
    "\n",
    "import requests\n",
    "import importlib\n",
    "import scipy.io as sio\n",
    "import urllib.request\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# download from url and write to file\n",
    "def write_from_url(url, filename):\n",
    "    r = requests.get(url)\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "# dictionairy\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "    \n",
    "def dict_from_module(module):\n",
    "    context = {}\n",
    "    for setting in dir(module):\n",
    "        # you can write your filter here\n",
    "        if not setting.startswith('_'):\n",
    "            context[setting] = getattr(module, setting)\n",
    "\n",
    "    return context\n",
    "\n",
    "# import setup file (.py) as module (dotdict)\n",
    "def read_setup(filename, new_read_path=None, old_read_path='/users/spraak/spchlab/public_html/data/timit/'):\n",
    "    \n",
    "    # load module\n",
    "    spec = importlib.util.spec_from_file_location(os.path.basename(filename), filename)\n",
    "    setup = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(setup)\n",
    "    \n",
    "    # convert to dict \n",
    "    setup = dict_from_module(setup)\n",
    "    setup = dotdict(setup)\n",
    "\n",
    "    # replace esat_path with root_url\n",
    "    if new_read_path is not None:\n",
    "        for k, v in setup.items():\n",
    "            if type(v) == str:\n",
    "                setup[k] = v.replace(old_read_path, new_read_path)\n",
    "            \n",
    "    return setup\n",
    "\n",
    "# loads all data in a matlab file at given url to the contents structure\n",
    "# this is working for MATLAB 7.0 files and older ; not hdf5 MATLAB 7.3 or more recent\n",
    "def load_matlab_from_url(url):\n",
    "    url_response = urllib.request.urlopen(url)\n",
    "    matio = io.BytesIO(url_response.read())\n",
    "    contents = sio.loadmat(matio,squeeze_me=True)\n",
    "    return(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "use_cuda_if_available = True\n",
    "if use_cuda_if_available:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root url\n",
    "root_url = 'https://homes.esat.kuleuven.be/~spchlab/data/timit/'\n",
    "\n",
    "# paths\n",
    "seg_url = root_url + 'segmentation/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFDNN(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=429, out_features=1024, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=768, bias=True)\n",
       "    (4): Sigmoid()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=768, out_features=512, bias=True)\n",
       "    (7): Sigmoid()\n",
       "    (8): Dropout(p=0.1, inplace=False)\n",
       "    (9): Linear(in_features=512, out_features=41, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "# = mfcc13, delta_delta2, meanvar, 11 frames, stride 2\n",
    "model_path = 'models/default/mfcc13dd2mv/N5s2/' \n",
    "\n",
    "# read checkpoint \n",
    "model_fobj = pyspch.read_fobj(root_url + model_path + 'model.pt')\n",
    "checkpoint = pyspch.nn.read_checkpoint(model_fobj, device)\n",
    "\n",
    "# unpack checkpoint (model, etc)\n",
    "setup, lab2idx, model, criterion, optimizer, scheduler = checkpoint\n",
    "setup = dotdict(setup)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate posteriors on utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 56218 The reasons for this dive seemed foolish now.']\n"
     ]
    }
   ],
   "source": [
    "# select file to visualize\n",
    "example = 'test/dr1/faks0/si2203'\n",
    "\n",
    "# audio\n",
    "example_audio, sample_rate = pyspch.audio.load(root_url + 'audio/' + example + \".wav\")\n",
    "\n",
    "# transcription + word segmentation \n",
    "example_txt = pyspch.read_txt(root_url + 'segmentation/' + example + \".txt\")\n",
    "example_wrd = pyspch.read_dataframe(root_url + 'segmentation/' + example + \".wrd\", sep=\" \", names=['t0','t1','wrd'])\n",
    "print(example_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization \n",
    "# - TODO: playable audio?\n",
    "# pyspch.display.PlotWaveform(waveform=example_audio,sample_rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aa': 0, 'ae': 1, 'ah': 2, 'ao': 3, 'aw': 4, 'er': 5, 'ay': 6, 'b': 7, 'ch': 8, 'd': 9, 'dh': 10, 'eh': 11, 'm': 12, 'ng': 13, 'ey': 14, 'f': 15, 'g': 16, 'hh': 17, 'ih': 18, 'iy': 19, 'jh': 20, 'k': 21, 'l': 22, 'n': 23, 'ow': 24, 'oy': 25, 'p': 26, 'r': 27, 's': 28, 'sh': 29, 't': 30, 'th': 31, 'uh': 32, 'uw': 33, 'v': 34, 'w': 35, 'y': 36, 'z': 37, 'zh': 38, 'sil': 39, 'cl': 40}\n"
     ]
    }
   ],
   "source": [
    "# timit61 -> timit41\n",
    "lab2lab = pyspch.timit.get_timit_mapping(\"timit61\", \"timit41\")\n",
    "\n",
    "# one-hot encoding \n",
    "print(lab2idx)\n",
    "\n",
    "# labels (phone segmentation)\n",
    "example_phn = pyspch.timit.read_seg_file(root_url + 'segmentation/' + example + \".phn\", fmt=\"float32\", dt=1/sample_rate)\n",
    "example_lab = pyspch.seg2lbls(example_phn) \n",
    "example_lab = [lab2lab[lbl] for lbl in example_lab]\n",
    "example_idx = [lab2idx[lbl] for lbl in example_lab] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature + modification + splicing\n",
    "example_mod = pyspch.sp.feature_extraction(example_audio, **setup.feature_args)\n",
    "example_spliced = pyspch.sp.splice_frames(example_mod, setup.sampler_args['N'], setup.sampler_args['stride']) # input\n",
    "\n",
    "# tensor\n",
    "example_X = torch.tensor(example_spliced).T.float().to(device)\n",
    "example_y = torch.tensor(example_idx).long().to(device)\n",
    "\n",
    "# prediction \n",
    "example_yp = model(example_X) # log probs\n",
    "example_yp = torch.nn.Softmax(dim=1)(example_yp) # probs"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b489421a811f1a4b6a0e5b207439d4f3161b795084ca1121df5f0f12d80926d7"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
