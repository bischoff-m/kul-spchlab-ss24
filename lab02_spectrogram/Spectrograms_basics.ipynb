{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrograms - Basic Usage\n",
    "\n",
    "+ ###### Author: Dirk Van Compernolle   \n",
    "+ ###### Modification History: 5/10/2021, 01/02/2023\n",
    "+ ###### Requires:  pyspch>=0.7   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the pip install command to install pyspch -- it is required!\n",
    "#\n",
    "#!pip install git+https://github.com/compi1234/pyspch.git\n",
    "#\n",
    "try:\n",
    "    import pyspch\n",
    "except ModuleNotFoundError:\n",
    "    try:\n",
    "        print(\n",
    "        \"\"\"\n",
    "        To enable this notebook on platforms as Google Colab, \n",
    "        install the pyspch package and dependencies by running following code:\n",
    "\n",
    "        !pip install git+https://github.com/compi1234/pyspch.git\n",
    "        \"\"\"\n",
    "        )\n",
    "    except ModuleNotFoundError:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do the imports #\n",
    "##################\n",
    "#\n",
    "%matplotlib inline\n",
    "import os,sys \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, Audio, HTML\n",
    "#   \n",
    "import pyspch.sp as Sps\n",
    "import pyspch.core as Spch\n",
    "import pyspch.display as Spd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# make notebook cells stretch over the full screen\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose and Background\n",
    "The interactive spectrogram visualizes speech in the time-frequency domain.\n",
    "Some form of time-frequency analysis is the first processing step in the human auditory system in equally so\n",
    "in speech recognition systems.\n",
    " \n",
    "A Fourier Spectrogram is obtained by letting a sliding window make short time spectra and by viewing this in a 2D heatmap\n",
    "we may see which frequencies are present at which moment in time.  \n",
    "\n",
    "In this notebook we focus on elementary usage\n",
    "\n",
    "- as a popular Time-Frequency view of speech and audio signals in which we may discover the cognitive relevant elements (sounds, acoustic events, ... )\n",
    "- where we want to create a visual impression that is consistent with our auditory perception.\n",
    " \n",
    "\n",
    "\n",
    "### Instructions\n",
    "- You should use\n",
    "> Spd.iSpectrogram()   \n",
    "which is equivalent to calling it with parameters:     \n",
    "> Spd.iSpectrogram(figwidth=12, dpi=120)     \n",
    "\n",
    "On most graphic card / displays these parameters will work fine.\n",
    "If on your display you observe a bad mismatch between character sizes in the UI and detail in the figures, then you can try to modify the default settings.   \n",
    "If sliders don't align well with plots,\n",
    "you may also need to adjust the size of your window. \n",
    "\n",
    "#### Audio and Segmentation File Input\n",
    "Suggested Files to choose from:     \n",
    "( in root directory: 'https://homes.esat.kuleuven.be/~spchlab/data/'):   \n",
    "- misc/friendly.wav  ... a 1 second speech fragment\n",
    "- misc/train.wav     ... a train whistle\n",
    "- timit/audio/train/dr1/fcfj0/si1027.wav   ... an example sentence from the TIMIT corpus\n",
    "\n",
    "#### Segmentations\n",
    "For the example speech files a number of segmentations are available (not all for each example). You can display them by entering the filename in the appropriate field.\n",
    "They just have different extensions: \".gra\" for grapheme or letter ,\n",
    "\".phn\" for phone, \".syl\" for syllable and \".wrd\" for word   \n",
    "Be aware that the segmentations may look slightly different in the waveform plot vs. spectrogram plot as segmentations that are given in msec's are rounded to the sample level in the first plot and to the frame level in the second one \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 1: Phonetic Segmentations\n",
    "\n",
    "1. setting up:\n",
    "    + work with iSpectrogram()\n",
    "    + load misc/friendly.wav and load also the phonetic segmentation in misc/friendly.phn (or graphemic misc/friendly.gra)\n",
    "    + set your audio at a comfortable loudness when you play the sentence\n",
    "2. focus on the first word 'friendly', evaluate the segmentations, listen and comment\n",
    "    + 'f-r-ih-n-d-l-iy'\n",
    "    + 'ih-n-d-l-iy' \n",
    "    + 'f' and 'f-r'\n",
    "    + what was your most striking observation\n",
    "    + to what extent do you agree with the given segmentation, based on perception, based on time waveform and based on spectrogram ?\n",
    "\n",
    "## Exercise 2: Spectrogram Parameters\n",
    "\n",
    "1. setting up:\n",
    "    + work with iSpectrogram()\n",
    "    + load again misc/friendly.was with its phonetic transcript (or some other speech wavfile)\n",
    "    + use sliders to select small segments and listen to them to verify the phonetic transcript\n",
    "2. adjust spectrogram parameters, always start from defaults (shift=10msec, length=25msec, preemphasis=.97)\n",
    "    + describe what you observed when deviating from the defaults\n",
    "    + for what parameters and in what way does the spectrogram deviate from speech perception ?\n",
    "    + choose as frame_length 10, 30, 50, 100 msec. Which values would you describe as good, acceptable, not acceptible and why ?\n",
    "    + choose as frame_shift 5,10, 20 msec. Which values would you describe as good, acceptable, not acceptable and why ?\n",
    "    + Have you discovered the Heisenberg principle for speech ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bcfd41a55f48c3b416691c649b2472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iSpectrogram(children=(VBox(children=(Output(layout=Layout(border_bottom='solid 1px black', border_left='solidâ€¦"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Spd.iSpectrogram(figwidth=12)                 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
